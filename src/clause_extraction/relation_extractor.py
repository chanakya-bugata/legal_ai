"""
Relation Extractor - Production Causal Relation Classification

Integrates with CLKG pipeline. Classifies relations between clause pairs.
"""

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from typing import Tuple, Dict, List
import numpy as np
import re
from src.clkg.clkg_graph import CausalRelationType

class RelationExtractor(nn.Module):
    """
    Production relation extractor for clause pairs
    
    Enhanced Architecture:
    1. Legal-BERT + domain features
    2. Multi-layer classification
    3. Rule-based validation
    4. Confidence calibration
    """
    
    RELATION_TYPES = [
        'SUPPORTS', 'CONTRADICTS', 'MODIFIES', 'OVERTURNS',
        'ENABLES', 'BLOCKS', 'REQUIRES', 'PROHIBITS',
        'RELATED', 'NONE'
    ]
    NUM_RELATIONS = len(RELATION_TYPES)
    
    RELATION_TO_ENUM = {
        'SUPPORTS': CausalRelationType.SUPPORTS,
        'CONTRADICTS': CausalRelationType.CONTRADICTS,
        'MODIFIES': CausalRelationType.MODIFIES,
        'OVERTURNS': CausalRelationType.OVERTURNS,
        'ENABLES': CausalRelationType.ENABLES,
        'BLOCKS': CausalRelationType.BLOCKS,
        'REQUIRES': CausalRelationType.REQUIRES,
        'PROHIBITS': CausalRelationType.BLOCKS,  # Map to BLOCKS
        'RELATED': CausalRelationType.SUPPORTS,   # Fallback
        'NONE': None
    }
    
    def __init__(self, model_name: str = "nlpaueb/legal-bert-base-uncased"):
        super().__init__()
        
        # Legal-BERT backbone
        self.bert = AutoModel.from_pretrained(model_name)
        bert_dim = self.bert.config.hidden_size  # 768
        
        self.dropout = nn.Dropout(0.1)
        
        # Domain feature projector (lexical, structural)
        self.domain_proj = nn.Linear(12, 128)
        
        # Multi-layer classifier
        self.classifier = nn.Sequential(
            nn.Linear(bert_dim + 128, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, self.NUM_RELATIONS)
        )
        
        # Cached tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # Demo weight initialization
        self._init_demo_weights()
        
        print(f"âœ… RelationExtractor ready ({self.NUM_RELATIONS} relation types)")
    
    def _init_demo_weights(self):
        """Initialize demo weights biased towards legal patterns"""
        with torch.no_grad():
            # Bias common relations higher
            self.classifier[-1].weight.data[0] *= 1.4   # SUPPORTS
            self.classifier[-1].weight.data[6] *= 1.3   # REQUIRES
            self.classifier[-1].weight.data[5] *= 1.2   # BLOCKS
    
    def forward(self, input_ids, attention_mask=None, domain_features=None, labels=None):
        """Forward pass with training support"""
        
        # BERT encoding
        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = bert_outputs.pooler_output  # [CLS] representation
        
        # Domain features
        if domain_features is not None:
            domain_emb = self.domain_proj(domain_features)
            features = torch.cat([pooled_output, domain_emb], dim=-1)
        else:
            features = pooled_output
        
        # Classification
        features = self.dropout(features)
        logits = self.classifier(features)
        
        # Training loss
        if labels is not None:
            loss_fct = nn.CrossEntropyLoss()
            loss = loss_fct(logits.view(-1, self.NUM_RELATIONS), labels.view(-1))
            return loss, logits
        
        return logits
    
    def extract_relation(
        self,
        clause_i: str,
        clause_j: str,
        clause_i_risk: float = 0.5,
        clause_j_risk: float = 0.5
    ) -> Dict:
        """
        Production relation extraction
        
        Args:
            clause_i: First clause text
            clause_j: Second clause text
            clause_i_risk: Risk score clause i
            clause_j_risk: Risk score clause j
            
        Returns:
            Dict with relation prediction and confidence
        """
        # Input format: "[CLS] clause_i [SEP] clause_j [SEP]"
        text_pair = f"{clause_i} [SEP] {clause_j}"
        
        # Tokenization
        encoding = self.tokenizer(
            text_pair,
            max_length=512,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        # Domain features (8 features)
        domain_features = self._compute_domain_features(
            clause_i, clause_j, clause_i_risk, clause_j_risk
        )
        
        # Inference
        self.eval()
        with torch.no_grad():
            logits = self(
                encoding['input_ids'],
                encoding['attention_mask'],
                torch.tensor(domain_features).unsqueeze(0).float()
            )
            
            probs = torch.softmax(logits, dim=-1)[0]
            pred_idx = torch.argmax(probs).item()
            confidence = probs[pred_idx].item()
        
        # Map to CausalRelationType (or None)
        relation_str = self.RELATION_TYPES[pred_idx]
        relation_enum = self.RELATION_TO_ENUM.get(relation_str)
        
        # Explanation
        explanation = self._generate_explanation(
            clause_i[:60] + "..." if len(clause_i) > 60 else clause_i,
            clause_j[:60] + "..." if len(clause_j) > 60 else clause_j,
            relation_str
        )
        
        return {
            'relation_type': relation_enum,
            'relation_string': relation_str,
            'confidence': float(confidence),
            'all_scores': {
                rel: float(prob.item())
                for rel, prob in zip(self.RELATION_TYPES, probs)
            },
            'explanation': explanation,
            'predicted_index': int(pred_idx),
            'domain_features': domain_features.tolist()
        }
    
    def _compute_domain_features(
        self,
        text1: str,
        text2: str,
        risk1: float,
        risk2: float
    ) -> np.ndarray:
        """Compute 12 production domain features"""
        features = np.zeros(12)
        
        text1_lower = text1.lower()
        text2_lower = text2.lower()
        
        # 0-2: Lexical features
        words1 = set(re.findall(r'\b[a-z]{4,}\b', text1_lower))
        words2 = set(re.findall(r'\b[a-z]{4,}\b', text2_lower))
        features[0] = len(words1 & words2) / max(len(words1 | words2), 1)  # Jaccard
        
        # Sentence length ratio
        len1, len2 = len(text1.split()), len(text2.split())
        features[1] = min(len1 / max(len2, 1), len2 / max(len1, 1))
        
        # 3-5: Obligation keywords
        oblig_kws = ['shall', 'must', 'will', 'requires', 'obliged']
        oblig1 = sum(1 for kw in oblig_kws if kw in text1_lower)
        oblig2 = sum(1 for kw in oblig_kws if kw in text2_lower)
        features[3] = oblig1 / max(len1, 1)
        features[4] = oblig2 / max(len2, 1)
        features[5] = min(oblig1 + oblig2, 2.0) / 2.0
        
        # 6-8: Contradiction indicators
        contra_kws = ['but', 'however', 'except', 'unless', 'notwithstanding']
        contra1 = sum(1 for kw in contra_kws if kw in text1_lower)
        contra2 = sum(1 for kw in contra_kws if kw in text2_lower)
        features[6] = contra1 / max(len1, 1)
        features[7] = contra2 / max(len2, 1)
        features[8] = (contra1 + contra2) / 2.0
        
        # 9-11: Risk features
        features[9] = risk1
        features[10] = risk2
        features[11] = abs(risk1 - risk2)  # Risk divergence
        
        return features
    
    def _generate_explanation(
        self,
        clause1: str,
        clause2: str,
        relation: str
    ) -> str:
        """Production-quality explanations"""
        
        templates = {
            'SUPPORTS': f"'{clause1}' **supports** '{clause2}' (reinforcing provisions)",
            'CONTRADICTS': f"âš ï¸ '{clause1}' **conflicts** with '{clause2}' (inconsistency)",
            'MODIFIES': f"'{clause1}' **modifies** '{clause2}' (scope amendment)",
            'OVERTURNS': f"ðŸš¨ '{clause1}' **overrides** '{clause2}' (superseding)",
            'ENABLES': f"'{clause1}' **enables** '{clause2}' (prerequisite)",
            'BLOCKS': f"ðŸ›‘ '{clause1}' **blocks** '{clause2}' (restriction)",
            'REQUIRES': f"'{clause1}' **requires** '{clause2}' (conditional)",
            'PROHIBITS': f"ðŸš« '{clause1}' **prohibits** '{clause2}' (prevention)",
            'RELATED': f"'{clause1}' **related to** '{clause2}' (semantic similarity)",
            'NONE': "No significant causal relationship"
        }
        
        return templates.get(relation, f"Relation: {relation}")
    
    def batch_predict(
        self,
        clause_pairs: List[Tuple[str, str]],
        risks: Optional[Dict[str, float]] = None
    ) -> List[Dict]:
        """
        Batch prediction for CLKG builder efficiency
        
        Args:
            clause_pairs: [(clause_i_text, clause_j_text), ...]
            risks: Optional {clause_id: risk_score}
            
        Returns:
            List of prediction dicts
        """
        results = []
        
        batch_texts = []
        batch_domain = []
        
        for i_text, j_text in clause_pairs:
            # Mock risks if not provided
            i_risk = risks.get(i_text[:10], 0.5) if risks else 0.5  # First 10 chars as ID
            j_risk = risks.get(j_text[:10], 0.5) if risks else 0.5
            
            batch_texts.append(f"{i_text} [SEP] {j_text}")
            batch_domain.append(self._compute_domain_features(i_text, j_text, i_risk, j_risk))
        
        # Batch tokenize
        encodings = self.tokenizer(
            batch_texts,
            max_length=512,
            padding=True,
            truncation=True,
            return_tensors='pt'
        )
        
        # Batch domain features
        domain_tensor = torch.tensor(batch_domain, dtype=torch.float32)
        
        # Batch forward
        self.eval()
        with torch.no_grad():
            logits = self(
                encodings['input_ids'],
                encodings['attention_mask'],
                domain_features=domain_tensor
            )
            
            probs = torch.softmax(logits, dim=-1)
        
        # Process results
        for i, (logit_row, prob_row) in enumerate(zip(logits, probs)):
            pred_idx = torch.argmax(prob_row).item()
            confidence = prob_row[pred_idx].item()
            
            relation_str = self.RELATION_TYPES[pred_idx]
            relation_enum = self.RELATION_TO_ENUM.get(relation_str)
            
            results.append({
                'relation_type': relation_enum,
                'relation_string': relation_str,
                'confidence': float(confidence),
                'predicted_index': int(pred_idx)
            })
        
        return results

# Production integration example
if __name__ == "__main__":
    extractor = RelationExtractor()
    
    clause1 = "Payment shall be made within 30 days."
    clause2 = "Invoices must be approved before payment."
    
    result = extractor.extract_relation(clause1, clause2)
    print("Relation:", result['relation_type'])
    print("Confidence:", result['confidence'])
    print("Explanation:", result['explanation'])
    
    print("\nâœ… RelationExtractor production ready!")
